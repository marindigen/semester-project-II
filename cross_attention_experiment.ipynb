{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# for tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with cross attention\n",
    "In this experiment, we sample data not only from uniform distribution but from variety of distributions. We then use this data for encoder and feed its output throught cross-attention mechanism to the decoder. The decoder takes the sequence with missing tokens and tries to fill in the gaps.\n",
    "\n",
    "### Architecture\n",
    "- We use multihead attention for the encoder and vanilla attention for the decoder.\n",
    "- In the encoder, before splitting heads I \"merge\" the 5 sequences through linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'semester-project/'\n",
      "/Users/mariayuffa/semester-project\n"
     ]
    }
   ],
   "source": [
    "cd semester-project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train sequences of proteins sampled from Boltzmann distribution: (1000, 200)\n",
      "Loaded test sequences of proteins sampled from Boltzmann distribution: (1000, 200)\n",
      "Loaded train sequences of proteins for encoder distribution: (1000, 5, 200)\n",
      "Loaded test sequences of proteins for encoder distribution: (1000, 5, 200)\n"
     ]
    }
   ],
   "source": [
    "# Sequences for decoder\n",
    "final_chains_train = np.load('data/final_chains_T=1_num_iters=400_train.npy')\n",
    "print(\"Loaded train sequences of proteins sampled from Boltzmann distribution:\", final_chains_train.shape)\n",
    "\n",
    "final_chains_test = np.load('data/final_chains_T=1_num_iters=400_test.npy')\n",
    "print(\"Loaded test sequences of proteins sampled from Boltzmann distribution:\", final_chains_test.shape)\n",
    "\n",
    "\n",
    "# Sequences for encoder\n",
    "k = 0\n",
    "final_chains_encoder_train = np.zeros((1000,5,200))\n",
    "final_chains_encoder_train[:,0,:] = np.load('data/final_chains_T=1_num_iters=400_J=10_test.npy') \n",
    "final_chains_encoder_test = np.zeros((1000,5,200))\n",
    "final_chains_encoder_test[:,0,:] = np.load('data/final_chains_T=1_num_iters=400_J=10_test.npy') \n",
    "for i in range(20,100,20):\n",
    "    k+=1\n",
    "    final_chains_encoder_train[:,k,:] = np.load('data/final_chains_T=1_num_iters=400_J='+str(i)+'_train.npy')\n",
    "    final_chains_encoder_test[:,k,:] = np.load('data/final_chains_T=1_num_iters=400_J='+str(i)+'_test.npy') \n",
    "\n",
    "print(\"Loaded train sequences of proteins for encoder distribution:\", final_chains_encoder_train.shape)\n",
    "print(\"Loaded test sequences of proteins for encoder distribution:\", final_chains_encoder_test.shape)\n",
    "\n",
    "tensor_samples_train = torch.tensor(final_chains_encoder_train, dtype=torch.float32) \n",
    "tensor_samples_test = torch.tensor(final_chains_encoder_test, dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for different distributions\n",
    "distributions = [{\"type\": \"normal\", \"mean\": 0, \"std\": 1},\n",
    "        {\"type\": \"uniform\", \"low\": -1, \"high\": 1},\n",
    "        {\"type\": \"exponential\", \"scale\": 1},\n",
    "        {\"type\": \"gamma\", \"scale\": 1},\n",
    "        {\"type\": \"poisson\", \"lam\": 1.0}]\n",
    "\n",
    "def sample_data(num_samples, distributions, len_of_seq):\n",
    "    # Define the parameters for different distributions\n",
    "    \n",
    "    # Initialize the tensor to store the samples\n",
    "    all_samples = torch.zeros(len(distributions), num_samples, len_of_seq)\n",
    "    \n",
    "    # Sample data from each distribution\n",
    "    for i in range(len(distributions)):\n",
    "        distr = distributions[i]\n",
    "        if distr[\"type\"] == \"normal\":\n",
    "            samples = np.random.normal(distr[\"mean\"], distr[\"std\"], (num_samples, len_of_seq))\n",
    "            samples = np.where(samples >= 0, 1, -1)\n",
    "        elif distr[\"type\"] == \"uniform\":\n",
    "            samples = np.random.uniform(distr[\"low\"], distr[\"high\"], (num_samples, len_of_seq))\n",
    "            samples = np.where(samples >= 0, 1, -1)\n",
    "        elif distr[\"type\"] == \"exponential\":\n",
    "            samples = np.random.exponential(distr[\"scale\"], (num_samples, len_of_seq))\n",
    "            samples = np.where(samples >= distr[\"scale\"], 1, -1)\n",
    "        elif distr[\"type\"] == \"gamma\":\n",
    "            samples = np.random.poisson(distr[\"scale\"], (num_samples, len_of_seq))\n",
    "            samples = np.where(samples >= np.mean(samples), 1, -1)\n",
    "        elif distr[\"type\"] == \"poisson\":\n",
    "            samples = np.random.poisson(distr[\"lam\"], (num_samples, len_of_seq))\n",
    "            samples = np.where(samples >= np.mean(samples), 1, -1)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distribution type\")\n",
    "        \n",
    "        # Store the samples in the tensor\n",
    "        all_samples[i] = torch.tensor(samples, dtype=torch.float32)\n",
    "    \n",
    "    return all_samples.reshape(num_samples, len(distributions), len_of_seq)\n",
    "\n",
    "# Example usage\n",
    "#tensor_samples_train = sample_data(1000, distributions, 200)  # 5 distributions, 1000 samples each, length of sequence 10\n",
    "#print(tensor_samples_train.shape)\n",
    "\n",
    "#tensor_samples_test = sample_data(1000, distributions, 200)  # 5 distributions, 1000 samples each, length of sequence 10\n",
    "#print(tensor_samples_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = torch.tensor([np.random.choice([-1, 1], size=20) for _ in range(1000)])\n",
    "#data_train_dec = torch.tensor([np.random.choice([-1, 1], size=20) for _ in range(1000)])\n",
    "#data_test = torch.tensor([np.random.choice([-1, 1], size=20) for _ in range(400)])\n",
    "#data_test_dec = torch.tensor([np.random.choice([-1, 1], size=20) for _ in range(400)])\n",
    "\n",
    "def one_hot_encoding(seq, vocab):\n",
    "    if isinstance(seq, int):\n",
    "        one_hot = torch.zeros(1, len(vocab), dtype=int)\n",
    "        one_hot[:, vocab[seq]] = 1\n",
    "    else:\n",
    "        one_hot = torch.zeros((len(seq), len(vocab)), dtype=int)\n",
    "        for i, spin in enumerate(seq):\n",
    "            one_hot[i, vocab[spin]] = 1\n",
    "    return one_hot\n",
    "\n",
    "def mask_random_spins(sequence, vocab, pos=10, mask_token=2):\n",
    "    \"\"\"\n",
    "    Mask one random spin in a sequence of protein spins.\n",
    "    \n",
    "    Parameters:\n",
    "    - sequence: a list or sequence of spins (integers)\n",
    "    - mask_token: the token used to mask a spin (default is 2)\n",
    "    \n",
    "    Returns:\n",
    "    - masked_sequence: a sequence similar to the input but with one spin masked\n",
    "    - masked_position: the position of the spin that was masked\n",
    "    \"\"\"\n",
    "    # Ensure the sequence can be converted to a list for masking\n",
    "    sequence_list = sequence.numpy().tolist() if isinstance(sequence, torch.Tensor) else list(sequence)\n",
    "    # Choose a random position to mask, excluding the first spin\n",
    "    mask_positions = random.sample(range(len(sequence)), pos)\n",
    "    \n",
    "    # Mask the chosen position\n",
    "    masked_sequence = sequence_list.copy()\n",
    "    for mask_position in mask_positions:\n",
    "        masked_sequence[mask_position] = mask_token\n",
    "\n",
    "    # Create an array of zeros with shape (len(sequence), len(vocab))\n",
    "    one_hot = one_hot_encoding(masked_sequence, vocab)\n",
    "        \n",
    "    return torch.tensor(one_hot, dtype=torch.float), torch.tensor(mask_positions, dtype=torch.long)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert embed_dim % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = embed_dim // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(embed_dim, embed_dim) # Linear layer for query \n",
    "        self.W_k = nn.Linear(embed_dim, embed_dim)\n",
    "        self.W_v = nn.Linear(embed_dim, embed_dim)\n",
    "        self.W_o = nn.Linear(embed_dim, embed_dim) # Output layer to ensure that dimensionality matches the model's expected dimensionality\n",
    "        \n",
    "        self.combine_heads = nn.Linear(num_heads, 1)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, embed_dim = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "     \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        #print(\"x somewhere:\", x.shape)\n",
    "        #print(\"seqeunce length:\",seq_length)\n",
    "        #print(\"d model dim:\",self.d_model)\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size,seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        #print(\"shape of Q before splitting heads:\", Q.shape)\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        #print(\"shape of Q after splitting heads:\", Q.shape)\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        #print(\" before W_o:\", self.combine_heads(attn_output.permute(1,2,0)).squeeze(-1).shape)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n",
    "    \n",
    "class VanillaAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, a, max_seq_length, num_spins=3, dropout_rate=0.0):\n",
    "        super(VanillaAttention, self).__init__()\n",
    "        self.word_embeddings = nn.Linear(num_spins, embed_dim)\n",
    "        self.position_embeddings = nn.Embedding(max_seq_length, embed_dim)\n",
    "        self.a = a  # parameter controlling how important positions are\n",
    "        self.value_weight = nn.Linear(embed_dim, embed_dim)\n",
    "        self.query_weight = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key_weight = nn.Linear(embed_dim, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, embed_dim)  # output layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, s, enc_output):\n",
    "\n",
    "        position_ids = torch.arange(s.size(0), dtype=torch.long)\n",
    "        #x = self.word_embeddings(s) + self.a*self.position_embeddings(position_ids)\n",
    "        x = s + self.a*self.position_embeddings(position_ids)\n",
    "        \n",
    "        query = self.query_weight(x)\n",
    "        key = self.key_weight(enc_output)\n",
    "        values = self.value_weight(enc_output)\n",
    "        \n",
    "        # Simple attention score calculation (Dot product): this is equivalent to the interaction matrix\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1))  # Transpose last two dimensions for matrix multiplication\n",
    "        scores = torch.softmax(scores, dim=-1)  # Apply softmax to scores to get probabilities\n",
    "\n",
    "        # Apply attention scores to values\n",
    "        attn_output = torch.matmul(scores, values)\n",
    "\n",
    "        # Sum over the sequence length dimensions\n",
    "        #attn_output = attn_output.sum(dim=1)\n",
    "        output = self.fc(self.dropout(attn_output)) # should have size (20,3)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, proj_layer_dim, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(embed_dim=embed_dim, num_heads=len(distributions))\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model=embed_dim, d_ff=proj_layer_dim)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(len(distributions),1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x.permute(1,2,0)).permute(2,0,1)\n",
    "        attn_output = self.self_attn(x, x, x)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, a, max_seq_length, num_spins, proj_layer_dim, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = VanillaAttention(embed_dim=embed_dim, a=a, max_seq_length=max_seq_length, num_spins=num_spins, dropout_rate=dropout)# masking one of the word in the sequence\n",
    "        self.cross_attn = VanillaAttention(embed_dim=embed_dim, a=a, max_seq_length=max_seq_length, num_spins=num_spins, dropout_rate=dropout)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model=embed_dim, d_ff=proj_layer_dim)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.norm3 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output):\n",
    "        enc_output = enc_output.squeeze(0)\n",
    "        attn_output = self.self_attn(x, x)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        #x = x.sum(dim=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        print(self.pe.shape)\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, embed_dim, a, max_seq_length, num_spins, proj_layer_dim, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        #self.encoder_embedding = nn.Embedding(num_spins, embed_dim)\n",
    "        #self.decoder_embedding = nn.Embedding(num_spins, embed_dim)\n",
    "        self.word_embeddings = nn.Linear(num_spins, embed_dim)\n",
    "\n",
    "        #self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        #self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.encoder_layer = EncoderLayer(embed_dim, proj_layer_dim, dropout)\n",
    "        self.decoder_layer = DecoderLayer(embed_dim, a, max_seq_length, num_spins, proj_layer_dim, dropout)\n",
    "        self.fc = nn.Linear(embed_dim, num_spins)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        #src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        #src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        #tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "        src_embedded = self.word_embeddings(src)\n",
    "        tgt_embedded = self.word_embeddings(tgt)\n",
    "        enc_output = self.encoder_layer(src_embedded)\n",
    "        dec_output = self.decoder_layer(tgt_embedded, enc_output)\n",
    "        output = self.fc(dec_output)\n",
    "        #print(\"output of the transformer:\", output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/data_exp_distr_run_8_mask_pos=10')\n",
    "\n",
    "def evaluate(model, data_test, data_test_dec, vocab, criterion, device=0):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    for i, data in tqdm.tqdm(enumerate(data_test), total=len(data_test)):\n",
    "        # Get the inputs\n",
    "        input_seq_enc = data\n",
    "        input_seq_dec = data_test_dec[i]\n",
    "        \n",
    "        input_encoder_one_hot = torch.stack([one_hot_encoding(input_seq_enc[i].tolist(), vocab) for i in range(len(input_seq_enc))], dim=0)\n",
    "        input_encoder_one_hot = torch.tensor(input_encoder_one_hot, dtype=torch.float)\n",
    "\n",
    "        input_decoder_one_hot = one_hot_encoding(input_seq_dec.tolist(), vocab)\n",
    "        # mask a token\n",
    "        masked_sequence_dec, positions = mask_random_spins(input_seq_dec, vocab, mask_token=2)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model.forward(input_encoder_one_hot, masked_sequence_dec)\n",
    "        #predicted_tokens = F.softmax(outputs, dim=-1) # don't need to use softmax here\n",
    "        predictions = outputs[positions]\n",
    "\n",
    "        target_tokens = torch.where(input_decoder_one_hot[positions]==1)[1] #target_token = input_seq[position]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(predictions, target_tokens)\n",
    "        epoch_loss += loss.item()\n",
    "    #model.train()\n",
    "    return epoch_loss / len(data_test)\n",
    "\n",
    "def train(model, data_train, data_train_dec, data_test, data_test_dec, vocab, optimizer, criterion, num_epochs=15, device=0):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    best_eval_loss = 1e-3 # used to do early stopping\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(num_epochs), leave=False, position=0):\n",
    "        running_loss = 0\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for i, data in tqdm.tqdm(enumerate(data_train), total=len(data_train)):\n",
    "            # Get the inputs\n",
    "            input_seq_enc = data\n",
    "            input_seq_dec = data_train_dec[i]\n",
    "\n",
    "            input_encoder_one_hot = torch.stack([one_hot_encoding(input_seq_enc[i].tolist(), vocab) for i in range(len(input_seq_enc))], dim=0)\n",
    "            input_encoder_one_hot = torch.tensor(input_encoder_one_hot, dtype=torch.float)\n",
    "\n",
    "            input_decoder_one_hot = one_hot_encoding(input_seq_dec.tolist(), vocab)\n",
    "\n",
    "            # mask a token in decoder\n",
    "            masked_sequence_dec, positions = mask_random_spins(input_seq_dec, vocab, mask_token=2)\n",
    "\n",
    "            # Forward pass\n",
    "            prediction = model.forward(input_encoder_one_hot, masked_sequence_dec) #masked_sequence[masked_position]\n",
    "            \n",
    "            #predicted_tokens = F.softmax(prediction, dim=-1)\n",
    "            predictions = prediction[positions]\n",
    "            target_tokens = torch.where(input_decoder_one_hot[positions]==1)[1] #input_seq[masked_position]\n",
    "            \n",
    "            # Compute loss\n",
    "            #print(\"model predictions:\", predictions.shape)\n",
    "            #print(\"target:\", target_tokens.shape)\n",
    "            loss = criterion(predictions, target_tokens)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9. :    # print every 10 mini-batches\n",
    "                writer.add_scalar(\"Running Loss\", running_loss / 100, epoch)\n",
    "                #print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        print(f'Epoch {epoch + 1} | Train Loss: {(epoch_loss / len(data)):.4f}')\n",
    "        writer.add_scalar(\"Train Loss\", epoch_loss / len(data), epoch)\n",
    "        eval_loss = evaluate(model, data_test, data_test_dec, vocab, criterion, device=device)\n",
    "        writer.add_scalar(\"Eval Loss\", eval_loss, epoch)\n",
    "        print(f'Epoch {epoch + 1} | Eval Loss: {(eval_loss):.4f}')\n",
    "        \n",
    "        # Perform early stopping based on eval loss\n",
    "        if eval_loss < best_eval_loss:\n",
    "            return epoch_loss / len(data_train)\n",
    "    return epoch_loss / len(data_train)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters \n",
    "vocab_size = 3\n",
    "vocab = {-1:0,1:1,2:2} \n",
    "L = 200\n",
    "embedding_dim = 200\n",
    "proj_layer_dim = 128\n",
    "hidden_dim = 200\n",
    "num_layers = 1 # have to adapt the model for 2 and 3 layers\n",
    "dropout_rate = 0.0\n",
    "lr = 1e-3\n",
    "num_sequences = 1000\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]/var/folders/mg/44g5ch495hdc8x4_5mq3dsdm0000gn/T/ipykernel_62106/1090187125.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_encoder_one_hot = torch.tensor(input_encoder_one_hot, dtype=torch.float)\n",
      "/var/folders/mg/44g5ch495hdc8x4_5mq3dsdm0000gn/T/ipykernel_62106/3482267866.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(one_hot, dtype=torch.float), torch.tensor(mask_positions, dtype=torch.long)\n",
      "100%|██████████| 1000/1000 [00:17<00:00, 57.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 143.6028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mg/44g5ch495hdc8x4_5mq3dsdm0000gn/T/ipykernel_62106/1090187125.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_encoder_one_hot = torch.tensor(input_encoder_one_hot, dtype=torch.float)\n",
      "100%|██████████| 1000/1000 [00:07<00:00, 136.66it/s]\n",
      "  7%|▋         | 1/15 [00:24<05:44, 24.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Eval Loss: 0.6926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:16<00:00, 60.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 139.5907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 134.95it/s]\n",
      " 13%|█▎        | 2/15 [00:48<05:14, 24.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Eval Loss: 0.6943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:18<00:00, 53.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 139.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 130.17it/s]\n",
      " 20%|██        | 3/15 [01:14<05:01, 25.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Eval Loss: 0.6968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 56.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 140.1765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 133.67it/s]\n",
      " 27%|██▋       | 4/15 [01:40<04:37, 25.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Eval Loss: 0.6965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 56.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 138.8215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 130.49it/s]\n",
      " 33%|███▎      | 5/15 [02:05<04:12, 25.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Eval Loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 57.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 139.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 132.44it/s]\n",
      " 40%|████      | 6/15 [02:30<03:46, 25.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Eval Loss: 0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 56.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 139.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 125.62it/s]\n",
      " 47%|████▋     | 7/15 [02:55<03:22, 25.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Eval Loss: 0.6944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 58.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 139.2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 133.77it/s]\n",
      " 53%|█████▎    | 8/15 [03:20<02:55, 25.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Eval Loss: 0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:18<00:00, 53.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 138.9476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 132.05it/s]\n",
      " 60%|██████    | 9/15 [03:46<02:32, 25.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Eval Loss: 0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 56.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 139.1637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 130.91it/s]\n",
      " 67%|██████▋   | 10/15 [04:12<02:07, 25.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Eval Loss: 0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:18<00:00, 55.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 138.8269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 131.70it/s]\n",
      " 73%|███████▎  | 11/15 [04:37<01:42, 25.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Eval Loss: 0.6922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:16<00:00, 59.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 139.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 131.02it/s]\n",
      " 80%|████████  | 12/15 [05:02<01:15, 25.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Eval Loss: 0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:18<00:00, 53.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 138.8113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 135.58it/s]\n",
      " 87%|████████▋ | 13/15 [05:28<00:50, 25.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Eval Loss: 0.6924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 57.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 138.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 128.33it/s]\n",
      " 93%|█████████▎| 14/15 [05:53<00:25, 25.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Eval Loss: 0.6926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 57.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 138.7279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 133.64it/s]\n",
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Eval Loss: 0.6923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6936394318938255"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "model = Transformer(embed_dim=embedding_dim, a=0, max_seq_length=L, num_spins=3, proj_layer_dim=128, dropout=dropout_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(model, tensor_samples_train, final_chains_train, tensor_samples_test, final_chains_test, vocab, optimizer, criterion, device=device)\n",
    "#torch.save(model.state_dict(), 'models/lstm_scratch.pt')\n",
    "#evaluate(model, test_dataloader, criterion, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To save only the decoder layer weights\n",
    "torch.save(model.decoder_layer.state_dict(), 'model_decoder/decoder_weights.pth')\n",
    "\n",
    "# If you need to load these weights later\n",
    "decoder_weights = torch.load('model_decoder/decoder_weights.pth')\n",
    "model.decoder_layer.load_state_dict(decoder_weights)\n",
    "\n",
    "# Save the weights of the FC layer\n",
    "torch.save(model.fc.state_dict(), 'model_decoder/transformer_fc_weights.pth')\n",
    "\n",
    "# To load these weights back into the FC layer later\n",
    "fc_weights = torch.load('model_decoder/transformer_fc_weights.pth')\n",
    "model.fc.load_state_dict(fc_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation study\n",
    "In this study we remove the encoder when testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerAblated(nn.Module):\n",
    "    def __init__(self, embed_dim, a, max_seq_length, num_spins, proj_layer_dim, dropout):\n",
    "        super(TransformerAblated, self).__init__()\n",
    "        self.word_embeddings = nn.Linear(num_spins, embed_dim)\n",
    "        self.decoder_layer = DecoderLayer(embed_dim, a, max_seq_length, num_spins, proj_layer_dim, dropout)\n",
    "        self.fc = nn.Linear(embed_dim, num_spins)\n",
    "\n",
    "    def forward(self, tgt):\n",
    "        tgt_embedded = self.word_embeddings(tgt)\n",
    "        dec_output = self.decoder_layer(tgt_embedded, tgt_embedded)\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the new model\n",
    "new_model = TransformerAblated(embed_dim=embedding_dim, a=0, max_seq_length=L, num_spins=3, proj_layer_dim=128, dropout=dropout_rate)\n",
    "\n",
    "# Load the saved decoder weights\n",
    "decoder_weights = torch.load('model_decoder/decoder_weights.pth')\n",
    "new_model.decoder_layer.load_state_dict(decoder_weights)\n",
    "\n",
    "# Load the saved FC weights\n",
    "fc_weights = torch.load('model_decoder/transformer_fc_weights.pth')\n",
    "new_model.fc.load_state_dict(fc_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/transformer_ablation_run_3')\n",
    "\n",
    "def evaluate(new_model, data_test, data_test_dec, vocab, criterion, device=0):\n",
    "    new_model.eval()\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    for i, data in tqdm.tqdm(enumerate(data_test), total=len(data_test)):\n",
    "        # Get the inputs\n",
    "        input_seq_dec = data_test_dec[i]\n",
    "        input_decoder_one_hot = one_hot_encoding(input_seq_dec.tolist(), vocab)\n",
    "        # mask a token\n",
    "        masked_sequence_dec, positions = mask_random_spins(input_seq_dec, vocab, mask_token=2)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = new_model.forward(masked_sequence_dec)\n",
    "        predicted_tokens = F.softmax(outputs, dim=-1)\n",
    "        predictions = predicted_tokens[positions]\n",
    "        target_tokens = torch.where(input_decoder_one_hot[positions]==1)[1]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(predictions, target_tokens)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(data_test)\n",
    "\n",
    "def train(model, new_model, data_train, data_train_dec, data_test, data_test_dec, vocab, optimizer, criterion, num_epochs=20, device=0):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    best_eval_loss = 1e-3 # used to do early stopping\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(num_epochs), leave=False, position=0):\n",
    "        running_loss = 0\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for i, data in tqdm.tqdm(enumerate(data_train), total=len(data_train)):\n",
    "            # Get the inputs\n",
    "            input_seq_enc = data\n",
    "            input_seq_dec = data_train_dec[i]\n",
    "\n",
    "            input_encoder_one_hot = torch.stack([one_hot_encoding(input_seq_enc[i].tolist(), vocab) for i in range(len(input_seq_enc))], dim=0)\n",
    "            input_encoder_one_hot = torch.tensor(input_encoder_one_hot, dtype=torch.float)\n",
    "\n",
    "            input_decoder_one_hot = one_hot_encoding(input_seq_dec.tolist(), vocab)\n",
    "\n",
    "            # mask a token in decoder\n",
    "            masked_sequence_dec, positions = mask_random_spins(input_seq_dec, vocab, mask_token=2)\n",
    "\n",
    "            # Forward pass\n",
    "            prediction = model.forward(input_encoder_one_hot, masked_sequence_dec) #masked_sequence[masked_position]\n",
    "            \n",
    "            predicted_tokens = F.softmax(prediction, dim=-1)\n",
    "            predictions = predicted_tokens[positions]\n",
    "            target_tokens = torch.where(input_decoder_one_hot[positions]==1)[1] #input_seq[masked_position]\n",
    "            \n",
    "            # Compute loss\n",
    "            #print(\"model prediction:\", prediction.shape)\n",
    "            #print(\"target:\", target_token.shape)\n",
    "            loss = criterion(predictions, target_tokens)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9. :    # print every 10 mini-batches\n",
    "                writer.add_scalar(\"Running Loss\", running_loss / 100, epoch)\n",
    "                #print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        new_model.decoder_layer = model.decoder_layer\n",
    "        new_model.fc = model.fc\n",
    "        print(f'Epoch {epoch + 1} | Train Loss: {(epoch_loss / len(data)):.4f}')\n",
    "        writer.add_scalar(\"Train Loss\", epoch_loss / len(data), epoch)\n",
    "        eval_loss = evaluate(new_model, data_test, data_test_dec, vocab, criterion, device=device)\n",
    "        writer.add_scalar(\"Eval Loss\", eval_loss, epoch)\n",
    "        print(f'Epoch {epoch + 1} | Eval Loss: {(eval_loss):.4f}')\n",
    "        \n",
    "        # Perform early stopping based on eval loss\n",
    "        if eval_loss < best_eval_loss:\n",
    "            return epoch_loss / len(data_train)\n",
    "    return epoch_loss / len(data_train)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 4\u001b[0m train(model, \u001b[43mnew_model\u001b[49m, tensor_samples_train, final_chains_train, tensor_samples_test, final_chains_test, vocab, optimizer, criterion, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Define the parameters \u001b[39;00m\n\u001b[1;32m      7\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(model, new_model, tensor_samples_train, final_chains_train, tensor_samples_test, final_chains_test, vocab, optimizer, criterion, device=device)\n",
    "\n",
    "# Define the parameters \n",
    "vocab_size = 3\n",
    "vocab = {-1:0,1:1,2:2} \n",
    "L = 200\n",
    "embedding_dim = 200\n",
    "proj_layer_dim = 128\n",
    "hidden_dim = 200\n",
    "num_layers = 1 # have to adapt the model for 2 and 3 layers\n",
    "dropout_rate = 0.0\n",
    "lr = 1e-3\n",
    "num_sequences = 1000\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_interactions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
