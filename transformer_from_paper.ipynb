{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A transformer-based model based on \"What does self-attention learn from Masked Language Modelling?\" paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core parts of the transformer\n",
    "- Separated position and spin\n",
    "- Single attention layer\n",
    "\n",
    "\n",
    "### Outline\n",
    "1. Vanilla attention implementation\n",
    "2. Factored attention implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(100,1000,300)\n",
    "idx = torch.randint(0,1000,(100,))\n",
    "# create masked_X, Y=model(masked_X)\n",
    "# X[:,idx,:]-Y[:,idx,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = torch.tensor([np.random.choice([-1, 1], size=20) for _ in range(1000)])\n",
    "data_test = torch.tensor([np.random.choice([-1, 1], size=20) for _ in range(100)])\n",
    "\n",
    "def one_hot_encoding(seq, vocab):\n",
    "    if isinstance(seq, int):\n",
    "        one_hot = torch.zeros(1, len(vocab), dtype=int)\n",
    "        one_hot[:, vocab[seq]] = 1\n",
    "    else:\n",
    "        one_hot = torch.zeros((len(seq), len(vocab)), dtype=int)\n",
    "        for i, spin in enumerate(seq):\n",
    "            one_hot[i, vocab[spin]] = 1\n",
    "    return one_hot\n",
    "\n",
    "def mask_random_spin(sequence, mask_token=2):\n",
    "    \"\"\"\n",
    "    Mask one random spin in a sequence of protein spins.\n",
    "    \n",
    "    Parameters:\n",
    "    - sequence: a list or sequence of spins (integers)\n",
    "    - mask_token: the token used to mask a spin (default is 2)\n",
    "    \n",
    "    Returns:\n",
    "    - masked_sequence: a sequence similar to the input but with one spin masked\n",
    "    - masked_position: the position of the spin that was masked\n",
    "    \"\"\"\n",
    "    # define vocabulary\n",
    "    vocab = {-1:0,1:1,2:2}\n",
    "    # Ensure the sequence can be converted to a list for masking\n",
    "    sequence_list = sequence.numpy().tolist() if isinstance(sequence, torch.Tensor) else list(sequence)\n",
    "    \n",
    "    # Choose a random position to mask, excluding the first spin\n",
    "    mask_position = random.randint(1, len(sequence_list) - 1)\n",
    "    \n",
    "    # Mask the chosen position\n",
    "    masked_sequence = sequence_list.copy()\n",
    "    masked_sequence[mask_position] = mask_token\n",
    "\n",
    "    # Create an array of zeros with shape (len(sequence), len(vocab))\n",
    "    #one_hot = np.zeros((len(sequence_list), len(vocab)), dtype=int)\n",
    "    #for i, spin in enumerate(masked_sequence):\n",
    "    #    one_hot[i, vocab[spin]] = 1\n",
    "    one_hot = one_hot_encoding(masked_sequence, vocab)\n",
    "    # Display the one-hot encoding of the masked spin\n",
    "    #mask_encoding = np.zeros((1, len(vocab)), dtype=int)\n",
    "    #mask_encoding[0, vocab[2]] = 1\n",
    "        \n",
    "    return torch.tensor(one_hot), torch.tensor(mask_position)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaAttentionTransformer(nn.Module):\n",
    "    def __init__(self, embed_dim, a, max_seq_length, num_spins=3, dropout_rate=0.0):\n",
    "        super(VanillaAttentionTransformer, self).__init__()\n",
    "        self.word_embeddings = nn.Linear(num_spins, embed_dim)\n",
    "        self.position_embeddings = nn.Embedding(max_seq_length, embed_dim)\n",
    "        self.a = a  # parameter controlling how important positions are\n",
    "        self.value_weight = nn.Linear(embed_dim, embed_dim)\n",
    "        self.query_weight = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key_weight = nn.Linear(embed_dim, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, num_spins)  # output layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, s, masked_token):\n",
    "        #if not isinstance(s, torch.Tensor):\n",
    "        s = torch.tensor(s, dtype=torch.float)\n",
    "        #if not isinstance(masked_token, torch.Tensor):\n",
    "        masked_token = torch.tensor(masked_token, dtype=torch.float)\n",
    "\n",
    "        position_ids = torch.arange(s.size(0), dtype=torch.long)\n",
    "        x = self.word_embeddings(s) + self.a*self.position_embeddings(position_ids)\n",
    "        \n",
    "        query = self.query_weight(x)\n",
    "        key = self.key_weight(x)\n",
    "        values = self.value_weight(x)\n",
    "        \n",
    "        # Simple attention score calculation (Dot product): this is equivalent to the interaction matrix\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1))  # Transpose last two dimensions for matrix multiplication\n",
    "        scores = torch.softmax(scores, dim=-1)  # Apply softmax to scores to get probabilities\n",
    "\n",
    "        # Apply attention scores to values\n",
    "        attn_output = torch.matmul(scores, values)\n",
    "\n",
    "        # Sum over the sequence length dimensions\n",
    "        #print(\"attention before summing:\", attn_output.shape)\n",
    "        attn_output = attn_output.sum(dim=0)\n",
    "        #print(\"attention after summing:\", attn_output.shape)\n",
    "        output = self.fc(self.dropout(attn_output))\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_test, vocab, criterion, device=0):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    for i, data in tqdm.tqdm(enumerate(data_test), total=len(data_test)):\n",
    "        # Get the inputs\n",
    "        input_seq = data\n",
    "        input_one_hot = one_hot_encoding(input_seq.tolist(), vocab)\n",
    "        # mask a token\n",
    "        masked_sequence, position = mask_random_spin(input_seq, mask_token=2)\n",
    "        # Forward pass\n",
    "        outputs = model.forward(masked_sequence, masked_sequence[position])\n",
    "\n",
    "        #output_token = F.log_softmax(outputs, dim=-1)\n",
    "        target_token = torch.argwhere(input_one_hot[position]==1).squeeze(0) #target_token = input_seq[position]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs.unsqueeze(0), target_token)\n",
    "        epoch_loss += loss.item()\n",
    "    #model.train()\n",
    "    return epoch_loss / len(data_test)\n",
    "\n",
    "def train(model, data_train, data_test, vocab, optimizer, criterion, num_epochs=8, device=0):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    best_eval_loss = 1e-3 # used to do early stopping\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(num_epochs), leave=False, position=0):\n",
    "        running_loss = 0\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for i, data in tqdm.tqdm(enumerate(data_train), total=len(data_train)):\n",
    "            # Get the inputs\n",
    "            input_seq = data\n",
    "            input_one_hot = one_hot_encoding(input_seq.tolist(), vocab)\n",
    "\n",
    "            # mask a token\n",
    "            masked_sequence, position = mask_random_spin(input_seq, mask_token=2)\n",
    "\n",
    "            # Forward pass\n",
    "            prediction = model.forward(masked_sequence, masked_sequence[position]) #masked_sequence[masked_position]\n",
    "            \n",
    "            #predicted_token = F.log_softmax(prediction, dim=-1)\n",
    "            target_token = torch.argwhere(input_one_hot[position]==1).squeeze(0) #input_seq[masked_position]\n",
    "            # Compute loss\n",
    "            #print(\"predicted_token:\", predicted_token)\n",
    "            #print(\"predicted_token:\", prediction)\n",
    "            #print(\"target token:\", target_token)\n",
    "            loss = criterion(prediction.unsqueeze(0), target_token)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Zero gradients, perform a backward pass, and update the weights.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9. :    # print every 10 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        print(f'Epoch {epoch + 1} | Train Loss: {(epoch_loss / len(data)):.4f}')\n",
    "        eval_loss = evaluate(model, data_test, vocab, criterion, device=device)\n",
    "        print(f'Epoch {epoch + 1} | Eval Loss: {(eval_loss):.4f}')\n",
    "        \n",
    "        # Perform early stopping based on eval loss\n",
    "        if eval_loss < best_eval_loss:\n",
    "            return epoch_loss / len(data_train)\n",
    "    return epoch_loss / len(data_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters \n",
    "vocab_size = 3\n",
    "vocab = {-1:0,1:1,2:2} \n",
    "L = 20\n",
    "embedding_dim = 20\n",
    "hidden_dim = 20\n",
    "num_layers = 1 # have to adapt the model for 2 and 3 layers\n",
    "dropout_rate = 0.0\n",
    "lr = 1e-3\n",
    "num_sequences = 1000\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/var/folders/mg/44g5ch495hdc8x4_5mq3dsdm0000gn/T/ipykernel_82546/2066114617.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(one_hot), torch.tensor(mask_position)\n",
      "/var/folders/mg/44g5ch495hdc8x4_5mq3dsdm0000gn/T/ipykernel_82546/10981384.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s = torch.tensor(s, dtype=torch.float)\n",
      "/var/folders/mg/44g5ch495hdc8x4_5mq3dsdm0000gn/T/ipykernel_82546/10981384.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_token = torch.tensor(masked_token, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.136\n",
      "[1,    20] loss: 0.089\n",
      "[1,    30] loss: 0.080\n",
      "[1,    40] loss: 0.056\n",
      "[1,    50] loss: 0.092\n",
      "[1,    60] loss: 0.068\n",
      "[1,    70] loss: 0.073\n",
      "[1,    80] loss: 0.071\n",
      "[1,    90] loss: 0.077\n",
      "[1,   100] loss: 0.067\n",
      "[1,   110] loss: 0.080\n",
      "[1,   120] loss: 0.065\n",
      "[1,   130] loss: 0.078\n",
      "[1,   140] loss: 0.066\n",
      "[1,   150] loss: 0.075\n",
      "[1,   160] loss: 0.061\n",
      "[1,   170] loss: 0.082\n",
      "[1,   180] loss: 0.079\n",
      "[1,   190] loss: 0.071\n",
      "[1,   200] loss: 0.073\n",
      "[1,   210] loss: 0.066\n",
      "[1,   220] loss: 0.085\n",
      "[1,   230] loss: 0.090\n",
      "[1,   240] loss: 0.081\n",
      "[1,   250] loss: 0.086\n",
      "[1,   260] loss: 0.065\n",
      "[1,   270] loss: 0.072\n",
      "[1,   280] loss: 0.070\n",
      "[1,   290] loss: 0.070\n",
      "[1,   300] loss: 0.066\n",
      "[1,   310] loss: 0.070\n",
      "[1,   320] loss: 0.074\n",
      "[1,   330] loss: 0.072\n",
      "[1,   340] loss: 0.050\n",
      "[1,   350] loss: 0.101\n",
      "[1,   360] loss: 0.062\n",
      "[1,   370] loss: 0.073\n",
      "[1,   380] loss: 0.067\n",
      "[1,   390] loss: 0.085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   400] loss: 0.079\n",
      "[1,   410] loss: 0.072\n",
      "[1,   420] loss: 0.072\n",
      "[1,   430] loss: 0.069\n",
      "[1,   440] loss: 0.069\n",
      "[1,   450] loss: 0.086\n",
      "[1,   460] loss: 0.075\n",
      "[1,   470] loss: 0.069\n",
      "[1,   480] loss: 0.094\n",
      "[1,   490] loss: 0.071\n",
      "[1,   500] loss: 0.089\n",
      "[1,   510] loss: 0.083\n",
      "[1,   520] loss: 0.047\n",
      "[1,   530] loss: 0.081\n",
      "[1,   540] loss: 0.078\n",
      "[1,   550] loss: 0.063\n",
      "[1,   560] loss: 0.073\n",
      "[1,   570] loss: 0.112\n",
      "[1,   580] loss: 0.082\n",
      "[1,   590] loss: 0.079\n",
      "[1,   600] loss: 0.073\n",
      "[1,   610] loss: 0.075\n",
      "[1,   620] loss: 0.101\n",
      "[1,   630] loss: 0.075\n",
      "[1,   640] loss: 0.079\n",
      "[1,   650] loss: 0.063\n",
      "[1,   660] loss: 0.093\n",
      "[1,   670] loss: 0.069\n",
      "[1,   680] loss: 0.059\n",
      "[1,   690] loss: 0.105\n",
      "[1,   700] loss: 0.070\n",
      "[1,   710] loss: 0.056\n",
      "[1,   720] loss: 0.087\n",
      "[1,   730] loss: 0.075\n",
      "[1,   740] loss: 0.070\n",
      "[1,   750] loss: 0.072\n",
      "[1,   760] loss: 0.072\n",
      "[1,   770] loss: 0.069\n",
      "[1,   780] loss: 0.067\n",
      "[1,   790] loss: 0.083\n",
      "[1,   800] loss: 0.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1911.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   810] loss: 0.070\n",
      "[1,   820] loss: 0.071\n",
      "[1,   830] loss: 0.072\n",
      "[1,   840] loss: 0.067\n",
      "[1,   850] loss: 0.073\n",
      "[1,   860] loss: 0.073\n",
      "[1,   870] loss: 0.065\n",
      "[1,   880] loss: 0.072\n",
      "[1,   890] loss: 0.069\n",
      "[1,   900] loss: 0.075\n",
      "[1,   910] loss: 0.065\n",
      "[1,   920] loss: 0.080\n",
      "[1,   930] loss: 0.079\n",
      "[1,   940] loss: 0.076\n",
      "[1,   950] loss: 0.069\n",
      "[1,   960] loss: 0.084\n",
      "[1,   970] loss: 0.069\n",
      "[1,   980] loss: 0.072\n",
      "[1,   990] loss: 0.077\n",
      "[1,  1000] loss: 0.065\n",
      "Epoch 1 | Train Loss: 37.5421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4792.67it/s]\n",
      " 12%|█▎        | 1/8 [00:00<00:03,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Eval Loss: 0.7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    10] loss: 0.061\n",
      "[2,    20] loss: 0.079\n",
      "[2,    30] loss: 0.073\n",
      "[2,    40] loss: 0.072\n",
      "[2,    50] loss: 0.072\n",
      "[2,    60] loss: 0.066\n",
      "[2,    70] loss: 0.084\n",
      "[2,    80] loss: 0.070\n",
      "[2,    90] loss: 0.070\n",
      "[2,   100] loss: 0.075\n",
      "[2,   110] loss: 0.068\n",
      "[2,   120] loss: 0.078\n",
      "[2,   130] loss: 0.067\n",
      "[2,   140] loss: 0.073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   150] loss: 0.072\n",
      "[2,   160] loss: 0.068\n",
      "[2,   170] loss: 0.060\n",
      "[2,   180] loss: 0.081\n",
      "[2,   190] loss: 0.086\n",
      "[2,   200] loss: 0.082\n",
      "[2,   210] loss: 0.069\n",
      "[2,   220] loss: 0.071\n",
      "[2,   230] loss: 0.074\n",
      "[2,   240] loss: 0.070\n",
      "[2,   250] loss: 0.066\n",
      "[2,   260] loss: 0.069\n",
      "[2,   270] loss: 0.081\n",
      "[2,   280] loss: 0.062\n",
      "[2,   290] loss: 0.053\n",
      "[2,   300] loss: 0.090\n",
      "[2,   310] loss: 0.043\n",
      "[2,   320] loss: 0.092\n",
      "[2,   330] loss: 0.075\n",
      "[2,   340] loss: 0.064\n",
      "[2,   350] loss: 0.075\n",
      "[2,   360] loss: 0.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   370] loss: 0.061\n",
      "[2,   380] loss: 0.081\n",
      "[2,   390] loss: 0.067\n",
      "[2,   400] loss: 0.072\n",
      "[2,   410] loss: 0.069\n",
      "[2,   420] loss: 0.074\n",
      "[2,   430] loss: 0.064\n",
      "[2,   440] loss: 0.045\n",
      "[2,   450] loss: 0.099\n",
      "[2,   460] loss: 0.074\n",
      "[2,   470] loss: 0.065\n",
      "[2,   480] loss: 0.071\n",
      "[2,   490] loss: 0.058\n",
      "[2,   500] loss: 0.054\n",
      "[2,   510] loss: 0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   520] loss: 0.072\n",
      "[2,   530] loss: 0.079\n",
      "[2,   540] loss: 0.074\n",
      "[2,   550] loss: 0.073\n",
      "[2,   560] loss: 0.067\n",
      "[2,   570] loss: 0.082\n",
      "[2,   580] loss: 0.074\n",
      "[2,   590] loss: 0.070\n",
      "[2,   600] loss: 0.062\n",
      "[2,   610] loss: 0.082\n",
      "[2,   620] loss: 0.070\n",
      "[2,   630] loss: 0.067\n",
      "[2,   640] loss: 0.078\n",
      "[2,   650] loss: 0.064\n",
      "[2,   660] loss: 0.066\n",
      "[2,   670] loss: 0.081\n",
      "[2,   680] loss: 0.090\n",
      "[2,   690] loss: 0.072\n",
      "[2,   700] loss: 0.069\n",
      "[2,   710] loss: 0.063\n",
      "[2,   720] loss: 0.089\n",
      "[2,   730] loss: 0.072\n",
      "[2,   740] loss: 0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   750] loss: 0.074\n",
      "[2,   760] loss: 0.064\n",
      "[2,   770] loss: 0.074\n",
      "[2,   780] loss: 0.062\n",
      "[2,   790] loss: 0.079\n",
      "[2,   800] loss: 0.071\n",
      "[2,   810] loss: 0.072\n",
      "[2,   820] loss: 0.070\n",
      "[2,   830] loss: 0.071\n",
      "[2,   840] loss: 0.072\n",
      "[2,   850] loss: 0.070\n",
      "[2,   860] loss: 0.071\n",
      "[2,   870] loss: 0.073\n",
      "[2,   880] loss: 0.071\n",
      "[2,   890] loss: 0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1836.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   900] loss: 0.072\n",
      "[2,   910] loss: 0.075\n",
      "[2,   920] loss: 0.069\n",
      "[2,   930] loss: 0.071\n",
      "[2,   940] loss: 0.071\n",
      "[2,   950] loss: 0.071\n",
      "[2,   960] loss: 0.066\n",
      "[2,   970] loss: 0.079\n",
      "[2,   980] loss: 0.072\n",
      "[2,   990] loss: 0.065\n",
      "[2,  1000] loss: 0.078\n",
      "Epoch 2 | Train Loss: 35.9532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4618.06it/s]\n",
      " 25%|██▌       | 2/8 [00:01<00:03,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Eval Loss: 0.7441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    10] loss: 0.076\n",
      "[3,    20] loss: 0.070\n",
      "[3,    30] loss: 0.068\n",
      "[3,    40] loss: 0.075\n",
      "[3,    50] loss: 0.068\n",
      "[3,    60] loss: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    70] loss: 0.070\n",
      "[3,    80] loss: 0.071\n",
      "[3,    90] loss: 0.070\n",
      "[3,   100] loss: 0.068\n",
      "[3,   110] loss: 0.074\n",
      "[3,   120] loss: 0.073\n",
      "[3,   130] loss: 0.072\n",
      "[3,   140] loss: 0.069\n",
      "[3,   150] loss: 0.074\n",
      "[3,   160] loss: 0.051\n",
      "[3,   170] loss: 0.064\n",
      "[3,   180] loss: 0.075\n",
      "[3,   190] loss: 0.086\n",
      "[3,   200] loss: 0.057\n",
      "[3,   210] loss: 0.068\n",
      "[3,   220] loss: 0.080\n",
      "[3,   230] loss: 0.069\n",
      "[3,   240] loss: 0.069\n",
      "[3,   250] loss: 0.070\n",
      "[3,   260] loss: 0.077\n",
      "[3,   270] loss: 0.077\n",
      "[3,   280] loss: 0.069\n",
      "[3,   290] loss: 0.076\n",
      "[3,   300] loss: 0.069\n",
      "[3,   310] loss: 0.068\n",
      "[3,   320] loss: 0.068\n",
      "[3,   330] loss: 0.069\n",
      "[3,   340] loss: 0.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   350] loss: 0.065\n",
      "[3,   360] loss: 0.074\n",
      "[3,   370] loss: 0.070\n",
      "[3,   380] loss: 0.068\n",
      "[3,   390] loss: 0.072\n",
      "[3,   400] loss: 0.071\n",
      "[3,   410] loss: 0.072\n",
      "[3,   420] loss: 0.066\n",
      "[3,   430] loss: 0.072\n",
      "[3,   440] loss: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   450] loss: 0.076\n",
      "[3,   460] loss: 0.066\n",
      "[3,   470] loss: 0.078\n",
      "[3,   480] loss: 0.071\n",
      "[3,   490] loss: 0.075\n",
      "[3,   500] loss: 0.062\n",
      "[3,   510] loss: 0.072\n",
      "[3,   520] loss: 0.094\n",
      "[3,   530] loss: 0.068\n",
      "[3,   540] loss: 0.070\n",
      "[3,   550] loss: 0.072\n",
      "[3,   560] loss: 0.062\n",
      "[3,   570] loss: 0.080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   580] loss: 0.071\n",
      "[3,   590] loss: 0.067\n",
      "[3,   600] loss: 0.060\n",
      "[3,   610] loss: 0.094\n",
      "[3,   620] loss: 0.065\n",
      "[3,   630] loss: 0.070\n",
      "[3,   640] loss: 0.073\n",
      "[3,   650] loss: 0.071\n",
      "[3,   660] loss: 0.065\n",
      "[3,   670] loss: 0.078\n",
      "[3,   680] loss: 0.072\n",
      "[3,   690] loss: 0.072\n",
      "[3,   700] loss: 0.069\n",
      "[3,   710] loss: 0.073\n",
      "[3,   720] loss: 0.071\n",
      "[3,   730] loss: 0.070\n",
      "[3,   740] loss: 0.068\n",
      "[3,   750] loss: 0.062\n",
      "[3,   760] loss: 0.077\n",
      "[3,   770] loss: 0.082\n",
      "[3,   780] loss: 0.067\n",
      "[3,   790] loss: 0.076\n",
      "[3,   800] loss: 0.065\n",
      "[3,   810] loss: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   820] loss: 0.074\n",
      "[3,   830] loss: 0.069\n",
      "[3,   840] loss: 0.072\n",
      "[3,   850] loss: 0.069\n",
      "[3,   860] loss: 0.068\n",
      "[3,   870] loss: 0.076\n",
      "[3,   880] loss: 0.072\n",
      "[3,   890] loss: 0.070\n",
      "[3,   900] loss: 0.071\n",
      "[3,   910] loss: 0.053\n",
      "[3,   920] loss: 0.078\n",
      "[3,   930] loss: 0.076\n",
      "[3,   940] loss: 0.067\n",
      "[3,   950] loss: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1802.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   960] loss: 0.068\n",
      "[3,   970] loss: 0.076\n",
      "[3,   980] loss: 0.080\n",
      "[3,   990] loss: 0.072\n",
      "[3,  1000] loss: 0.069\n",
      "Epoch 3 | Train Loss: 35.5575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4724.33it/s]\n",
      " 38%|███▊      | 3/8 [00:01<00:02,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Eval Loss: 0.6943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,    10] loss: 0.072\n",
      "[4,    20] loss: 0.071\n",
      "[4,    30] loss: 0.071\n",
      "[4,    40] loss: 0.063\n",
      "[4,    50] loss: 0.082\n",
      "[4,    60] loss: 0.066\n",
      "[4,    70] loss: 0.073\n",
      "[4,    80] loss: 0.069\n",
      "[4,    90] loss: 0.070\n",
      "[4,   100] loss: 0.075\n",
      "[4,   110] loss: 0.068\n",
      "[4,   120] loss: 0.072\n",
      "[4,   130] loss: 0.073\n",
      "[4,   140] loss: 0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   150] loss: 0.067\n",
      "[4,   160] loss: 0.070\n",
      "[4,   170] loss: 0.068\n",
      "[4,   180] loss: 0.068\n",
      "[4,   190] loss: 0.070\n",
      "[4,   200] loss: 0.065\n",
      "[4,   210] loss: 0.066\n",
      "[4,   220] loss: 0.074\n",
      "[4,   230] loss: 0.071\n",
      "[4,   240] loss: 0.072\n",
      "[4,   250] loss: 0.071\n",
      "[4,   260] loss: 0.070\n",
      "[4,   270] loss: 0.072\n",
      "[4,   280] loss: 0.072\n",
      "[4,   290] loss: 0.070\n",
      "[4,   300] loss: 0.066\n",
      "[4,   310] loss: 0.081\n",
      "[4,   320] loss: 0.071\n",
      "[4,   330] loss: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   340] loss: 0.071\n",
      "[4,   350] loss: 0.069\n",
      "[4,   360] loss: 0.070\n",
      "[4,   370] loss: 0.070\n",
      "[4,   380] loss: 0.066\n",
      "[4,   390] loss: 0.073\n",
      "[4,   400] loss: 0.072\n",
      "[4,   410] loss: 0.070\n",
      "[4,   420] loss: 0.063\n",
      "[4,   430] loss: 0.079\n",
      "[4,   440] loss: 0.061\n",
      "[4,   450] loss: 0.053\n",
      "[4,   460] loss: 0.068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   470] loss: 0.053\n",
      "[4,   480] loss: 0.089\n",
      "[4,   490] loss: 0.068\n",
      "[4,   500] loss: 0.082\n",
      "[4,   510] loss: 0.069\n",
      "[4,   520] loss: 0.067\n",
      "[4,   530] loss: 0.075\n",
      "[4,   540] loss: 0.072\n",
      "[4,   550] loss: 0.070\n",
      "[4,   560] loss: 0.073\n",
      "[4,   570] loss: 0.066\n",
      "[4,   580] loss: 0.068\n",
      "[4,   590] loss: 0.072\n",
      "[4,   600] loss: 0.071\n",
      "[4,   610] loss: 0.071\n",
      "[4,   620] loss: 0.068\n",
      "[4,   630] loss: 0.070\n",
      "[4,   640] loss: 0.065\n",
      "[4,   650] loss: 0.074\n",
      "[4,   660] loss: 0.071\n",
      "[4,   670] loss: 0.072\n",
      "[4,   680] loss: 0.072\n",
      "[4,   690] loss: 0.072\n",
      "[4,   700] loss: 0.074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   710] loss: 0.072\n",
      "[4,   720] loss: 0.070\n",
      "[4,   730] loss: 0.067\n",
      "[4,   740] loss: 0.070\n",
      "[4,   750] loss: 0.071\n",
      "[4,   760] loss: 0.071\n",
      "[4,   770] loss: 0.072\n",
      "[4,   780] loss: 0.066\n",
      "[4,   790] loss: 0.067\n",
      "[4,   800] loss: 0.060\n",
      "[4,   810] loss: 0.076\n",
      "[4,   820] loss: 0.084\n",
      "[4,   830] loss: 0.068\n",
      "[4,   840] loss: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   850] loss: 0.070\n",
      "[4,   860] loss: 0.068\n",
      "[4,   870] loss: 0.070\n",
      "[4,   880] loss: 0.070\n",
      "[4,   890] loss: 0.066\n",
      "[4,   900] loss: 0.078\n",
      "[4,   910] loss: 0.070\n",
      "[4,   920] loss: 0.069\n",
      "[4,   930] loss: 0.071\n",
      "[4,   940] loss: 0.071\n",
      "[4,   950] loss: 0.069\n",
      "[4,   960] loss: 0.070\n",
      "[4,   970] loss: 0.072\n",
      "[4,   980] loss: 0.068\n",
      "[4,   990] loss: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1752.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  1000] loss: 0.072\n",
      "Epoch 4 | Train Loss: 35.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4945.82it/s]\n",
      " 50%|█████     | 4/8 [00:02<00:02,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Eval Loss: 0.7072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,    10] loss: 0.068\n",
      "[5,    20] loss: 0.071\n",
      "[5,    30] loss: 0.080\n",
      "[5,    40] loss: 0.070\n",
      "[5,    50] loss: 0.071\n",
      "[5,    60] loss: 0.070\n",
      "[5,    70] loss: 0.070\n",
      "[5,    80] loss: 0.063\n",
      "[5,    90] loss: 0.064\n",
      "[5,   100] loss: 0.082\n",
      "[5,   110] loss: 0.073\n",
      "[5,   120] loss: 0.070\n",
      "[5,   130] loss: 0.069\n",
      "[5,   140] loss: 0.070\n",
      "[5,   150] loss: 0.068\n",
      "[5,   160] loss: 0.072\n",
      "[5,   170] loss: 0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   180] loss: 0.072\n",
      "[5,   190] loss: 0.069\n",
      "[5,   200] loss: 0.070\n",
      "[5,   210] loss: 0.068\n",
      "[5,   220] loss: 0.064\n",
      "[5,   230] loss: 0.076\n",
      "[5,   240] loss: 0.060\n",
      "[5,   250] loss: 0.068\n",
      "[5,   260] loss: 0.067\n",
      "[5,   270] loss: 0.073\n",
      "[5,   280] loss: 0.077\n",
      "[5,   290] loss: 0.066\n",
      "[5,   300] loss: 0.068\n",
      "[5,   310] loss: 0.074\n",
      "[5,   320] loss: 0.069\n",
      "[5,   330] loss: 0.070\n",
      "[5,   340] loss: 0.071\n",
      "[5,   350] loss: 0.071\n",
      "[5,   360] loss: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   370] loss: 0.073\n",
      "[5,   380] loss: 0.074\n",
      "[5,   390] loss: 0.073\n",
      "[5,   400] loss: 0.069\n",
      "[5,   410] loss: 0.068\n",
      "[5,   420] loss: 0.068\n",
      "[5,   430] loss: 0.072\n",
      "[5,   440] loss: 0.071\n",
      "[5,   450] loss: 0.069\n",
      "[5,   460] loss: 0.072\n",
      "[5,   470] loss: 0.070\n",
      "[5,   480] loss: 0.070\n",
      "[5,   490] loss: 0.070\n",
      "[5,   500] loss: 0.071\n",
      "[5,   510] loss: 0.070\n",
      "[5,   520] loss: 0.070\n",
      "[5,   530] loss: 0.070\n",
      "[5,   540] loss: 0.067\n",
      "[5,   550] loss: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   560] loss: 0.068\n",
      "[5,   570] loss: 0.069\n",
      "[5,   580] loss: 0.060\n",
      "[5,   590] loss: 0.063\n",
      "[5,   600] loss: 0.062\n",
      "[5,   610] loss: 0.070\n",
      "[5,   620] loss: 0.076\n",
      "[5,   630] loss: 0.080\n",
      "[5,   640] loss: 0.070\n",
      "[5,   650] loss: 0.069\n",
      "[5,   660] loss: 0.070\n",
      "[5,   670] loss: 0.071\n",
      "[5,   680] loss: 0.067\n",
      "[5,   690] loss: 0.060\n",
      "[5,   700] loss: 0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   710] loss: 0.061\n",
      "[5,   720] loss: 0.061\n",
      "[5,   730] loss: 0.080\n",
      "[5,   740] loss: 0.077\n",
      "[5,   750] loss: 0.077\n",
      "[5,   760] loss: 0.071\n",
      "[5,   770] loss: 0.068\n",
      "[5,   780] loss: 0.074\n",
      "[5,   790] loss: 0.070\n",
      "[5,   800] loss: 0.070\n",
      "[5,   810] loss: 0.070\n",
      "[5,   820] loss: 0.070\n",
      "[5,   830] loss: 0.070\n",
      "[5,   840] loss: 0.067\n",
      "[5,   850] loss: 0.070\n",
      "[5,   860] loss: 0.066\n",
      "[5,   870] loss: 0.076\n",
      "[5,   880] loss: 0.071\n",
      "[5,   890] loss: 0.066\n",
      "[5,   900] loss: 0.071\n",
      "[5,   910] loss: 0.073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   920] loss: 0.068\n",
      "[5,   930] loss: 0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1841.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   940] loss: 0.069\n",
      "[5,   950] loss: 0.065\n",
      "[5,   960] loss: 0.075\n",
      "[5,   970] loss: 0.072\n",
      "[5,   980] loss: 0.071\n",
      "[5,   990] loss: 0.070\n",
      "[5,  1000] loss: 0.068\n",
      "Epoch 5 | Train Loss: 35.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4914.01it/s]\n",
      " 62%|██████▎   | 5/8 [00:02<00:01,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Eval Loss: 0.7024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    10] loss: 0.065\n",
      "[6,    20] loss: 0.078\n",
      "[6,    30] loss: 0.070\n",
      "[6,    40] loss: 0.070\n",
      "[6,    50] loss: 0.070\n",
      "[6,    60] loss: 0.072\n",
      "[6,    70] loss: 0.070\n",
      "[6,    80] loss: 0.070\n",
      "[6,    90] loss: 0.065\n",
      "[6,   100] loss: 0.073\n",
      "[6,   110] loss: 0.070\n",
      "[6,   120] loss: 0.074\n",
      "[6,   130] loss: 0.070\n",
      "[6,   140] loss: 0.069\n",
      "[6,   150] loss: 0.070\n",
      "[6,   160] loss: 0.074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   170] loss: 0.069\n",
      "[6,   180] loss: 0.070\n",
      "[6,   190] loss: 0.069\n",
      "[6,   200] loss: 0.067\n",
      "[6,   210] loss: 0.070\n",
      "[6,   220] loss: 0.071\n",
      "[6,   230] loss: 0.063\n",
      "[6,   240] loss: 0.059\n",
      "[6,   250] loss: 0.087\n",
      "[6,   260] loss: 0.067\n",
      "[6,   270] loss: 0.073\n",
      "[6,   280] loss: 0.070\n",
      "[6,   290] loss: 0.068\n",
      "[6,   300] loss: 0.071\n",
      "[6,   310] loss: 0.070\n",
      "[6,   320] loss: 0.071\n",
      "[6,   330] loss: 0.070\n",
      "[6,   340] loss: 0.071\n",
      "[6,   350] loss: 0.070\n",
      "[6,   360] loss: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   370] loss: 0.070\n",
      "[6,   380] loss: 0.069\n",
      "[6,   390] loss: 0.070\n",
      "[6,   400] loss: 0.070\n",
      "[6,   410] loss: 0.070\n",
      "[6,   420] loss: 0.069\n",
      "[6,   430] loss: 0.066\n",
      "[6,   440] loss: 0.061\n",
      "[6,   450] loss: 0.073\n",
      "[6,   460] loss: 0.077\n",
      "[6,   470] loss: 0.071\n",
      "[6,   480] loss: 0.071\n",
      "[6,   490] loss: 0.070\n",
      "[6,   500] loss: 0.072\n",
      "[6,   510] loss: 0.070\n",
      "[6,   520] loss: 0.070\n",
      "[6,   530] loss: 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   540] loss: 0.069\n",
      "[6,   550] loss: 0.068\n",
      "[6,   560] loss: 0.066\n",
      "[6,   570] loss: 0.073\n",
      "[6,   580] loss: 0.072\n",
      "[6,   590] loss: 0.071\n",
      "[6,   600] loss: 0.070\n",
      "[6,   610] loss: 0.070\n",
      "[6,   620] loss: 0.070\n",
      "[6,   630] loss: 0.069\n",
      "[6,   640] loss: 0.068\n",
      "[6,   650] loss: 0.071\n",
      "[6,   660] loss: 0.068\n",
      "[6,   670] loss: 0.068\n",
      "[6,   680] loss: 0.068\n",
      "[6,   690] loss: 0.072\n",
      "[6,   700] loss: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   710] loss: 0.066\n",
      "[6,   720] loss: 0.068\n",
      "[6,   730] loss: 0.071\n",
      "[6,   740] loss: 0.071\n",
      "[6,   750] loss: 0.073\n",
      "[6,   760] loss: 0.071\n",
      "[6,   770] loss: 0.070\n",
      "[6,   780] loss: 0.070\n",
      "[6,   790] loss: 0.070\n",
      "[6,   800] loss: 0.070\n",
      "[6,   810] loss: 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   820] loss: 0.070\n",
      "[6,   830] loss: 0.068\n",
      "[6,   840] loss: 0.068\n",
      "[6,   850] loss: 0.068\n",
      "[6,   860] loss: 0.072\n",
      "[6,   870] loss: 0.071\n",
      "[6,   880] loss: 0.070\n",
      "[6,   890] loss: 0.067\n",
      "[6,   900] loss: 0.072\n",
      "[6,   910] loss: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1673.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   920] loss: 0.071\n",
      "[6,   930] loss: 0.069\n",
      "[6,   940] loss: 0.068\n",
      "[6,   950] loss: 0.071\n",
      "[6,   960] loss: 0.068\n",
      "[6,   970] loss: 0.068\n",
      "[6,   980] loss: 0.073\n",
      "[6,   990] loss: 0.070\n",
      "[6,  1000] loss: 0.067\n",
      "Epoch 6 | Train Loss: 34.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4820.43it/s]\n",
      " 75%|███████▌  | 6/8 [00:03<00:01,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Eval Loss: 0.7030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,    10] loss: 0.079\n",
      "[7,    20] loss: 0.070\n",
      "[7,    30] loss: 0.069\n",
      "[7,    40] loss: 0.066\n",
      "[7,    50] loss: 0.074\n",
      "[7,    60] loss: 0.072\n",
      "[7,    70] loss: 0.069\n",
      "[7,    80] loss: 0.072\n",
      "[7,    90] loss: 0.070\n",
      "[7,   100] loss: 0.073\n",
      "[7,   110] loss: 0.073\n",
      "[7,   120] loss: 0.069\n",
      "[7,   130] loss: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   140] loss: 0.071\n",
      "[7,   150] loss: 0.070\n",
      "[7,   160] loss: 0.073\n",
      "[7,   170] loss: 0.071\n",
      "[7,   180] loss: 0.066\n",
      "[7,   190] loss: 0.064\n",
      "[7,   200] loss: 0.075\n",
      "[7,   210] loss: 0.073\n",
      "[7,   220] loss: 0.072\n",
      "[7,   230] loss: 0.070\n",
      "[7,   240] loss: 0.069\n",
      "[7,   250] loss: 0.070\n",
      "[7,   260] loss: 0.070\n",
      "[7,   270] loss: 0.069\n",
      "[7,   280] loss: 0.071\n",
      "[7,   290] loss: 0.070\n",
      "[7,   300] loss: 0.070\n",
      "[7,   310] loss: 0.070\n",
      "[7,   320] loss: 0.069\n",
      "[7,   330] loss: 0.071\n",
      "[7,   340] loss: 0.069\n",
      "[7,   350] loss: 0.069\n",
      "[7,   360] loss: 0.069\n",
      "[7,   370] loss: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   380] loss: 0.070\n",
      "[7,   390] loss: 0.069\n",
      "[7,   400] loss: 0.069\n",
      "[7,   410] loss: 0.070\n",
      "[7,   420] loss: 0.069\n",
      "[7,   430] loss: 0.069\n",
      "[7,   440] loss: 0.072\n",
      "[7,   450] loss: 0.070\n",
      "[7,   460] loss: 0.069\n",
      "[7,   470] loss: 0.069\n",
      "[7,   480] loss: 0.069\n",
      "[7,   490] loss: 0.070\n",
      "[7,   500] loss: 0.070\n",
      "[7,   510] loss: 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   520] loss: 0.068\n",
      "[7,   530] loss: 0.070\n",
      "[7,   540] loss: 0.070\n",
      "[7,   550] loss: 0.071\n",
      "[7,   560] loss: 0.067\n",
      "[7,   570] loss: 0.068\n",
      "[7,   580] loss: 0.071\n",
      "[7,   590] loss: 0.063\n",
      "[7,   600] loss: 0.068\n",
      "[7,   610] loss: 0.071\n",
      "[7,   620] loss: 0.070\n",
      "[7,   630] loss: 0.073\n",
      "[7,   640] loss: 0.068\n",
      "[7,   650] loss: 0.067\n",
      "[7,   660] loss: 0.070\n",
      "[7,   670] loss: 0.068\n",
      "[7,   680] loss: 0.075\n",
      "[7,   690] loss: 0.074\n",
      "[7,   700] loss: 0.071\n",
      "[7,   710] loss: 0.071\n",
      "[7,   720] loss: 0.069\n",
      "[7,   730] loss: 0.070\n",
      "[7,   740] loss: 0.069\n",
      "[7,   750] loss: 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   760] loss: 0.069\n",
      "[7,   770] loss: 0.068\n",
      "[7,   780] loss: 0.070\n",
      "[7,   790] loss: 0.071\n",
      "[7,   800] loss: 0.070\n",
      "[7,   810] loss: 0.068\n",
      "[7,   820] loss: 0.067\n",
      "[7,   830] loss: 0.071\n",
      "[7,   840] loss: 0.071\n",
      "[7,   850] loss: 0.070\n",
      "[7,   860] loss: 0.070\n",
      "[7,   870] loss: 0.069\n",
      "[7,   880] loss: 0.069\n",
      "[7,   890] loss: 0.068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1850.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   900] loss: 0.071\n",
      "[7,   910] loss: 0.070\n",
      "[7,   920] loss: 0.072\n",
      "[7,   930] loss: 0.070\n",
      "[7,   940] loss: 0.069\n",
      "[7,   950] loss: 0.070\n",
      "[7,   960] loss: 0.070\n",
      "[7,   970] loss: 0.069\n",
      "[7,   980] loss: 0.069\n",
      "[7,   990] loss: 0.070\n",
      "[7,  1000] loss: 0.070\n",
      "Epoch 7 | Train Loss: 34.9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4848.01it/s]\n",
      " 88%|████████▊ | 7/8 [00:04<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Eval Loss: 0.6925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,    10] loss: 0.070\n",
      "[8,    20] loss: 0.069\n",
      "[8,    30] loss: 0.071\n",
      "[8,    40] loss: 0.068\n",
      "[8,    50] loss: 0.071\n",
      "[8,    60] loss: 0.070\n",
      "[8,    70] loss: 0.068\n",
      "[8,    80] loss: 0.065\n",
      "[8,    90] loss: 0.071\n",
      "[8,   100] loss: 0.070\n",
      "[8,   110] loss: 0.075\n",
      "[8,   120] loss: 0.068\n",
      "[8,   130] loss: 0.069\n",
      "[8,   140] loss: 0.070\n",
      "[8,   150] loss: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   160] loss: 0.071\n",
      "[8,   170] loss: 0.069\n",
      "[8,   180] loss: 0.069\n",
      "[8,   190] loss: 0.068\n",
      "[8,   200] loss: 0.074\n",
      "[8,   210] loss: 0.069\n",
      "[8,   220] loss: 0.070\n",
      "[8,   230] loss: 0.068\n",
      "[8,   240] loss: 0.069\n",
      "[8,   250] loss: 0.072\n",
      "[8,   260] loss: 0.070\n",
      "[8,   270] loss: 0.069\n",
      "[8,   280] loss: 0.070\n",
      "[8,   290] loss: 0.068\n",
      "[8,   300] loss: 0.074\n",
      "[8,   310] loss: 0.067\n",
      "[8,   320] loss: 0.071\n",
      "[8,   330] loss: 0.070\n",
      "[8,   340] loss: 0.069\n",
      "[8,   350] loss: 0.066\n",
      "[8,   360] loss: 0.068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   370] loss: 0.072\n",
      "[8,   380] loss: 0.062\n",
      "[8,   390] loss: 0.071\n",
      "[8,   400] loss: 0.076\n",
      "[8,   410] loss: 0.066\n",
      "[8,   420] loss: 0.068\n",
      "[8,   430] loss: 0.072\n",
      "[8,   440] loss: 0.066\n",
      "[8,   450] loss: 0.076\n",
      "[8,   460] loss: 0.073\n",
      "[8,   470] loss: 0.070\n",
      "[8,   480] loss: 0.069\n",
      "[8,   490] loss: 0.070\n",
      "[8,   500] loss: 0.070\n",
      "[8,   510] loss: 0.069\n",
      "[8,   520] loss: 0.070\n",
      "[8,   530] loss: 0.069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[8,   540] loss: 0.071\n",
      "[8,   550] loss: 0.069\n",
      "[8,   560] loss: 0.069\n",
      "[8,   570] loss: 0.070\n",
      "[8,   580] loss: 0.070\n",
      "[8,   590] loss: 0.069\n",
      "[8,   600] loss: 0.069\n",
      "[8,   610] loss: 0.070\n",
      "[8,   620] loss: 0.069\n",
      "[8,   630] loss: 0.069\n",
      "[8,   640] loss: 0.070\n",
      "[8,   650] loss: 0.069\n",
      "[8,   660] loss: 0.068\n",
      "[8,   670] loss: 0.072\n",
      "[8,   680] loss: 0.071\n",
      "[8,   690] loss: 0.069\n",
      "[8,   700] loss: 0.068\n",
      "[8,   710] loss: 0.069\n",
      "[8,   720] loss: 0.068\n",
      "[8,   730] loss: 0.070\n",
      "[8,   740] loss: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   750] loss: 0.069\n",
      "[8,   760] loss: 0.071\n",
      "[8,   770] loss: 0.068\n",
      "[8,   780] loss: 0.067\n",
      "[8,   790] loss: 0.066\n",
      "[8,   800] loss: 0.069\n",
      "[8,   810] loss: 0.076\n",
      "[8,   820] loss: 0.072\n",
      "[8,   830] loss: 0.068\n",
      "[8,   840] loss: 0.070\n",
      "[8,   850] loss: 0.070\n",
      "[8,   860] loss: 0.067\n",
      "[8,   870] loss: 0.065\n",
      "[8,   880] loss: 0.073\n",
      "[8,   890] loss: 0.069\n",
      "[8,   900] loss: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   910] loss: 0.070\n",
      "[8,   920] loss: 0.068\n",
      "[8,   930] loss: 0.073\n",
      "[8,   940] loss: 0.069\n",
      "[8,   950] loss: 0.070\n",
      "[8,   960] loss: 0.070\n",
      "[8,   970] loss: 0.070\n",
      "[8,   980] loss: 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1837.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   990] loss: 0.068\n",
      "[8,  1000] loss: 0.070\n",
      "Epoch 8 | Train Loss: 34.7998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 3967.00it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Eval Loss: 0.6881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6959957875907421"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "model = VanillaAttentionTransformer(embed_dim=embedding_dim, a=0, max_seq_length=L, num_spins=3, dropout_rate=dropout_rate)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(model, data_train, data_test, vocab, optimizer, criterion, device=device)\n",
    "#torch.save(model.state_dict(), 'models/lstm_scratch.pt')\n",
    "#evaluate(model, test_dataloader, criterion, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "- Do we pass through the sequence multiple times, each time masking different tokens or do we pass through the sequence once masking one random token?\n",
    "- Maybe we evaluate on how well the model predicts the other token in the sequence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaAttentionTransformer(nn.Module):\n",
    "    def __init__(self, embed_dim, a, max_seq_length, num_spins=3, dropout_rate=0.0):\n",
    "        super(VanillaAttentionTransformer, self).__init__()\n",
    "        self.word_embeddings = nn.Linear(num_spins, embed_dim)\n",
    "        self.position_embeddings = nn.Embedding(max_seq_length, embed_dim)\n",
    "        self.a = a # parameter controlling how important are positions\n",
    "        self.value_weight = nn.Linear(embed_dim, embed_dim)\n",
    "        self.query_weight = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key_weight = nn.Linear(embed_dim, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, num_spins) # output layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, s, masked_token):\n",
    "        position_ids = torch.arange(len(s), dtype=torch.long)\n",
    "        position_ids = position_ids\n",
    "        s = torch.tensor(s, dtype=torch.float)\n",
    "        masked_token = torch.tensor(masked_token, dtype=torch.float)\n",
    "        #print(\"the sequence with the masked token:\", s)\n",
    "        print(\"shape of position ids before embedding:\", position_ids.shape)\n",
    "        print(\"shape the sequence with the masked token:\", s.shape)\n",
    "        print(\"value of the word embedding:\", self.word_embeddings(s).shape)\n",
    "        print(\"positional embedding:\", self.position_embeddings(position_ids))\n",
    "        x = self.word_embeddings(s) + self.position_embeddings(position_ids)\n",
    "        query = self.query_weight(x)\n",
    "        key = self.key_weight(x)\n",
    "\n",
    "        values = self.value_weight(self.word_embeddings(s) + self.a*self.position_embeddings(position_ids)) # (batch_size,embed_dim)\n",
    "        exp_scaling = torch.exp(self.word_embeddings(masked_token) + self.position_embeddings(position_ids).T@query.T@key@(self.word_embeddings(s) + self.a*self.position_embeddings(position_ids)))\n",
    "        attn_output = torch.sum(exp_scaling/torch.sum(exp_scaling.sum(0))*values) # not sure it multiplies the way I want it to multiply - check\n",
    "        output = self.dropout(self.fc(attn_output))\n",
    "        return output\n",
    "    \n",
    "class FactoredAttentionTransformer(nn.Module):\n",
    "    def __init__(self, embed_dim, a, max_seq_length, num_spins=3, dropout_rate=0.0):\n",
    "        super(FactoredAttentionTransformer, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(num_spins, embed_dim)\n",
    "        self.word_embedding.weight.requires_grad = False\n",
    "        self.position_embeddings = nn.Embedding(max_seq_length, embed_dim)\n",
    "        self.a = a # parameter controlling how important are positions\n",
    "        self.value_weight = nn.Linear(embed_dim, embed_dim)\n",
    "        self.query_weight = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key_weight = nn.Linear(embed_dim, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, num_spins) # output layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, s, masked_token):\n",
    "        # masked token should be equal to 0\n",
    "        # masked_token = torch.tensor([0])\n",
    "        position_ids = torch.arange(len(s), dtype=torch.long)\n",
    "        position_ids = position_ids\n",
    "        x = self.word_embeddings(s) + self.position_embeddings(position_ids)\n",
    "        query = self.query_weight(x)\n",
    "        key = self.key_weight(x)\n",
    "\n",
    "        values = self.value_weight(self.word_embeddings(s)) # (embed_dim)\n",
    "        exp_scaling = torch.exp(self.word_embeddings(masked_token) + self.position_embeddings(position_ids).T@query.T@key@(self.word_embeddings(s) + self.a*self.position_embeddings(position_ids)))\n",
    "        attn_output = torch.sum(exp_scaling/torch.sum(exp_scaling.sum(0))*values) # not sure it multiplies the way I want it to multiply - check\n",
    "        output = self.fc(self.dropout(attn_output))\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_interactions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
